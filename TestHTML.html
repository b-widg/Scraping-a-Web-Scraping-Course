!<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Bootstrap Site</title>
    <!-- <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/5.0.0-alpha1/css/bootstrap.min.css"
      integrity="sha384-r4NyP46KrjDleawBgD5tp8Y7UzmLA05oM1iAEQ17CSuDqnUK2+k9luXQOfXJCJ4I"
      crossorigin="anonymous"
    /> -->
    <link rel="stylesheet" href="./style.css" />
    <!-- <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://stackpath.bootstrapcdn.com/bootstrap/5.0.0-alpha1/js/bootstrap.min.js"
      integrity="sha384-oesi62hOLfzrys4LxRF63OJCXdXDipiYWBnvTl9Y9/TRlw5xlKIEHpNyvvDShgf/"
      crossorigin="anonymous"
    ></script> -->
  </head>
  <body>
    <div class="classic-blog single">
      <div
        id="post-15592"
        class="
          post-15592 post
          type-post
          status-publish
          format-image
          has-post-thumbnail
          hentry
          category-lessons
          post_format-post-format-image
        "
      >
        <figure class="relative">
          <a
            href="https://4cawmi2va33i3w6dek1d7y1m-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/4-8.jpg"
            class="image-link-list fancybox-media"
            rel="portfolio"
            ><i class="icon icon-search"></i></a
          ><img
            width="800"
            height="450"
            src="https://4cawmi2va33i3w6dek1d7y1m-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/4-8.jpg"
            class="attachment-large size-large"
            alt=""
            loading="lazy"
            srcset="
              https://4cawmi2va33i3w6dek1d7y1m-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/4-8.jpg         800w,
              https://4cawmi2va33i3w6dek1d7y1m-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/4-8-300x169.jpg 300w,
              https://4cawmi2va33i3w6dek1d7y1m-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/4-8-768x432.jpg 768w,
              https://4cawmi2va33i3w6dek1d7y1m-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/4-8-440x248.jpg 440w
            "
            sizes="(max-width: 800px) 100vw, 800px"
          />
        </figure>
        <div class="post-content">
          <h1 class="post-title">
            Building Our Very First Web Scraper in 15 Minutes
          </h1>
          <div class="meta">
            <span class="date"> 27.07.2017 </span>

            <span class="category">
              <a
                href="https://gohighbrow.com/category/lessons/"
                rel="category tag"
                >|</a
              >
            </span>

            <span class="like"
              ><a
                href="#"
                class="zilla-likes"
                id="zilla-likes-15592"
                title="Like this"
                ><span class="zilla-likes-count">0</span>
                <span class="zilla-likes-postfix"></span></a
            ></span>
          </div>
          <p>
            <strong
              >Episode #4 of the course
              <a
                href="https://gohighbrow.com/portfolio/build-your-own-web-scraping-tool/"
                target="_blank"
                rel="noopener"
                >Build your own web scraping tool</a
              >
              by
              <a
                href="https://gohighbrow.com/team/hartley-brody/"
                target="_blank"
                rel="noopener"
                >Hartley Brody</a
              ></strong
            >
          </p>
          <p>&nbsp;</p>
          <p>
            Now that we have the concepts in hand and we’ve seen how to use your
            browser’s developer tools to inspect the HTTP requests and HTML
            response, we’re ready to get started with building our first web
            scraper.
          </p>
          <p>
            I usually use Python, since it’s very simple to write and has some
            great libraries for web scraping. If you’re already comfortable with
            another language, feel free to use something like PHP, Ruby, Java,
            or any other language. Remember, all we need is the ability to make
            HTTP requests and parse HTML responses, so it’s hard to go wrong
            with your technology choice.
          </p>
          <p>
            To build our first web scraper, we’ll need to start with a simple
            program that makes an HTTP request to the page we’re scraping.
            Here’s some sample Python code that accomplishes that.
          </p>
          <p style="padding-left: 30px">
            <span
              style="
                font-family: courier new, courier, lucida sans typewriter,
                  lucida typewriter, monospace;
              "
              >import requests</span
            >
          </p>
          <p style="padding-left: 30px">
            <span
              style="
                font-family: courier new, courier, lucida sans typewriter,
                  lucida typewriter, monospace;
              "
              ><b>r = requests.get(</b>“https://scrapethissite.com/pages/<b
                >“)</b
              ><br />
              print r.status_code == requests.codes.ok</span
            >
          </p>
          <p>
            You’ll see that—to make the HTTP request—we’re not only using the
            URL of the page, we’re also telling
            <a href="http://docs.python-requests.org/en/master/"
              >the Python requests library</a
            >
            to make a GET request to this page, since that’s the type of request
            we saw when we were inspecting it earlier in our browser’s developer
            tools.
          </p>
          <p>
            Now that we’ve built a simple program that makes a request, let’s
            take a look at how to handle the response.
          </p>
          <p>
            Parsing and structuring HTML responses is a surprisingly difficult
            task, even for simple websites. Instead of doing it all ourselves,
            it’s much better to use a free, pre-written library of someone
            else’s code to make the job much easier.
          </p>
          <p>
            In Python, the most popular library to use for this task is
            <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
              >Beautiful Soup</a
            >. Once we give it the HTML of the page we got back from the server,
            it will make it easy for us to find the HTML patterns we saw when we
            inspected the page earlier.
          </p>
          <p style="padding-left: 30px">
            <span
              style="
                font-family: courier new, courier, lucida sans typewriter,
                  lucida typewriter, monospace;
              "
              >import requests<br />
              from bs4 import BeautifulSoup</span
            >
          </p>
          <p style="padding-left: 30px">
            <span
              style="
                font-family: courier new, courier, lucida sans typewriter,
                  lucida typewriter, monospace;
              "
              >r = requests.get(“https://scrapethissite.com/pages/”)<br />
              print r.status_code == requests.codes.ok</span
            >
          </p>
          <p style="padding-left: 30px">
            <span
              style="
                font-family: courier new, courier, lucida sans typewriter,
                  lucida typewriter, monospace;
              "
              ><b>soup = BeautifulSoup(</b>r.text, “html.parser<b>“)</b
              ><b><br /> </b>print <b>soup.find(“</b>h3<b>“, “</b>page-title<b
                >“).text</b
              ></span
            >
          </p>
          <p>
            There we go! Once we run that program, we’ll see that it makes the
            HTTP request, parses the HTML response, and then finds the exact
            piece of data we were looking for on the page.
          </p>
          <p>Not too complex, was it?</p>
          <p>
            This was just a simple example, where all the data we were
            extracting was on one page. In a more realistic scenario, your web
            scraper will need to visit many different pages to find all the data
            you want to extract.
          </p>
          <p>
            We’ll take a look at a few patterns for that in the next lesson.
          </p>
          <p>&nbsp;</p>
          <p><b>Recommended book</b></p>
          <p>
            <b
              ><a href="http://amzn.to/2uZWq0v"
                ><i>Python Web Scraping</i> by Katharine Jarmul, Richard
                Lawson</a
              ></b
            >
          </p>
          <p>&nbsp;</p>
          <p><strong>Share with friends</strong></p>
          <script
            type="text/javascript"
            src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js"
            data-dojo-config="usePlainJson: true, isDebug: false"
          ></script>
          <script type="text/javascript">
            window.dojoRequire(['mojo/signup-forms/Loader'], function (L) {
              L.start({
                baseUrl: 'mc.us8.list-manage.com',
                uuid: '51c6d69760513a5e5e4f75b29',
                lid: '6360113d97',
                uniqueMethods: true,
              });
            });
          </script>
          <div class="meta tags"></div>

          <div class="share-links">
            <ul>
              <li>
                <a
                  class="btn share-facebook"
                  target="_blank"
                  href="https://www.facebook.com/share.php?u=https://gohighbrow.com/building-our-very-first-web-scraper-in-15-minutes/"
                  onclick="return ebor_fb_like()"
                  >Like</a
                >
              </li>
              <li>
                <a
                  class="btn share-twitter"
                  target="_blank"
                  href="https://twitter.com/share?url=https://gohighbrow.com/building-our-very-first-web-scraper-in-15-minutes/"
                  onclick="return ebor_tweet()"
                  >Tweet</a
                >
              </li>
              <li>
                <a
                  class="btn share-pinterest"
                  target="_blank"
                  href="https://pinterest.com/pin/create/button/?url=https://gohighbrow.com/building-our-very-first-web-scraper-in-15-minutes/"
                  onclick="return ebor_fb_pin()"
                  >Pin it</a
                >
              </li>
            </ul>
          </div>

          <script type="text/javascript">
            function ebor_fb_like() {
              window.open(
                'https://www.facebook.com/sharer.php?u=https://gohighbrow.com/building-our-very-first-web-scraper-in-15-minutes/&t=building-our-very-first-web-scraper-in-15-minutes',
                'sharer',
                'toolbar=0,status=0,width=626,height=436'
              );
              return false;
            }
            function ebor_tweet() {
              window.open(
                'https://twitter.com/share?url=https://gohighbrow.com/building-our-very-first-web-scraper-in-15-minutes/&t=building-our-very-first-web-scraper-in-15-minutes',
                'sharer',
                'toolbar=0,status=0,width=626,height=436'
              );
              return false;
            }
            function ebor_pin() {
              window.open(
                'https://pinterest.com/pin/create/button/?url=https://gohighbrow.com/building-our-very-first-web-scraper-in-15-minutes/&media=https://gohighbrow.com/wp-content/uploads/2017/07/4-8.jpg&description=building-our-very-first-web-scraper-in-15-minutes',
                'sharer',
                'toolbar=0,status=0,width=626,height=436'
              );
              return false;
            }
          </script>
        </div>
      </div>
      <!--/.post -->
    </div>
    <!--/.grid-blog -->
  </body>
</html>
